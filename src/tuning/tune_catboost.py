import os
import json
import argparse
import numpy as np
import pandas as pd
import optuna
from typing import Dict, Any

from catboost import CatBoostClassifier

from src.models.modeling_pipeline import month_folds, ing_hubs_datathon_metric, oof_composite_monthwise


def load_data() -> tuple[pd.DataFrame, pd.Series, pd.Series]:
    # Prefer root-level cached artifacts if present
    X_path = 'X_train.pkl'
    y_path = 'y_train.pkl'
    ref_path = 'ref_dates.pkl'
    if not (os.path.exists(X_path) and os.path.exists(y_path) and os.path.exists(ref_path)):
        # Fallback to outputs/ or data/processed if needed (extend here if your project differs)
        raise FileNotFoundError("Expected X_train.pkl, y_train.pkl, ref_dates.pkl at repo root.")
    X = pd.read_pickle(X_path)
    y = pd.read_pickle(y_path)
    ref_obj = pd.read_pickle(ref_path)
    if isinstance(ref_obj, pd.DataFrame):
        if 'ref_date' in ref_obj.columns:
            ref = ref_obj['ref_date']
        else:
            ref = ref_obj.iloc[:, 0]
    elif isinstance(ref_obj, pd.Series):
        ref = ref_obj
    else:
        ref = pd.Series(np.asarray(ref_obj))
    ref = pd.to_datetime(ref).astype(str)
    return X, pd.Series(y), pd.Series(ref)


def suggest_params(trial: optuna.trial.Trial, base_seed: int = 42) -> Dict[str, Any]:
    params: Dict[str, Any] = {
        'loss_function': 'Logloss',
        'eval_metric': 'AUC',
        'iterations': 4000,
        'od_type': 'Iter',
        'od_wait': 200,
        'task_type': 'CPU',
        'thread_count': -1,
        'bootstrap_type': 'Bayesian',
        'random_seed': trial.suggest_int('random_seed', 1, 10_000),
    }
    params['depth'] = trial.suggest_int('depth', 4, 8)
    params['learning_rate'] = trial.suggest_float('learning_rate', 0.02, 0.10, log=True)
    params['l2_leaf_reg'] = trial.suggest_float('l2_leaf_reg', 1.0, 20.0)
    params['bagging_temperature'] = trial.suggest_float('bagging_temperature', 0.0, 1.0)
    params['random_strength'] = trial.suggest_float('random_strength', 0.0, 1.0)
    params['border_count'] = trial.suggest_int('border_count', 128, 254)
    return params


def objective(trial: optuna.trial.Trial, X: pd.DataFrame, y: pd.Series, ref_dates: pd.Series) -> float:
    params = suggest_params(trial)

    # Compute auto scale_pos_weight from training prevalence
    pos = float(y.sum())
    neg = float(len(y) - pos)
    spw = (neg / pos) if pos > 0 else 1.0

    # Time folds: last 6 months, gap 1 by default
    folds = list(month_folds(ref_dates, last_n=6, gap=1))
    if not folds:
        raise optuna.TrialPruned("No folds produced.")

    oof = np.zeros(len(X), dtype=float)

    for fold_id, (tr_idx, va_idx, mlabel) in enumerate(folds, 1):
        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]
        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]

        p = dict(params)
        # Respect Bayesian bootstrap; avoid subsample clash
        p.pop('subsample', None)
        p['scale_pos_weight'] = spw
        model = CatBoostClassifier(**p)
        model.fit(
            X_tr, y_tr,
            eval_set=(X_va, y_va),
            verbose=False
        )

        pv = model.predict_proba(X_va)[:, 1].astype(float)
        oof[va_idx] = pv

    # Month-wise composite aggregation for score
    score = oof_composite_monthwise(y, oof, ref_dates=ref_dates, last_n_months=6)
    return float(score)


def save_best(best_params: Dict[str, Any], out_dir: str = 'models') -> None:
    os.makedirs(out_dir, exist_ok=True)
    # Persist to JSON
    with open(os.path.join(out_dir, 'tuned_cat_params.json'), 'w', encoding='utf-8') as f:
        json.dump(best_params, f, indent=2)

    # Update or create optimized_params.py with OPTIMIZED_CAT_PARAMS
    opt_py = os.path.join(out_dir, 'optimized_params.py')
    lines = []
    if os.path.exists(opt_py):
        with open(opt_py, 'r', encoding='utf-8') as f:
            lines = f.readlines()

    # Simple approach: write or replace OPTIMIZED_CAT_PARAMS block
    block = [
        "# Auto-generated by tune_catboost.py\n",
        "OPTIMIZED_CAT_PARAMS = " + json.dumps(best_params, indent=2) + "\n",
    ]
    # Filter out existing line starting with OPTIMIZED_CAT_PARAMS
    new_lines = [ln for ln in lines if not ln.strip().startswith('OPTIMIZED_CAT_PARAMS')]
    new_lines.extend(block)
    with open(opt_py, 'w', encoding='utf-8') as f:
        f.writelines(new_lines)

    # For backward compatibility, also mirror at repo root optimized_params.py if present
    root_opt = 'optimized_params.py'
    try:
        if os.path.exists(root_opt):
            with open(root_opt, 'r', encoding='utf-8') as f:
                root_lines = f.readlines()
            root_new = [ln for ln in root_lines if not ln.strip().startswith('OPTIMIZED_CAT_PARAMS')]
            root_new.extend(block)
            with open(root_opt, 'w', encoding='utf-8') as f:
                f.writelines(root_new)
        else:
            with open(root_opt, 'w', encoding='utf-8') as f:
                f.writelines(block)
    except Exception:
        pass


def main():
    parser = argparse.ArgumentParser(description='Optuna tuner for CatBoost with month-wise composite metric')
    parser.add_argument('--trials', type=int, default=50)
    parser.add_argument('--study', type=str, default='cat_tuning')
    parser.add_argument('--seed', type=int, default=42)
    args = parser.parse_args()

    X, y, ref_dates = load_data()

    sampler = optuna.samplers.TPESampler(seed=args.seed)
    pruner = optuna.pruners.MedianPruner(n_warmup_steps=5)
    study = optuna.create_study(direction='maximize', study_name=args.study, sampler=sampler, pruner=pruner)

    def _obj(trial: optuna.trial.Trial) -> float:
        return objective(trial, X, y, ref_dates)

    study.optimize(_obj, n_trials=args.trials, show_progress_bar=True)

    if len(study.trials) == 0 or study.best_trial is None:
        print('No completed trials; aborting save.')
        return

    # Build best params from the best trial's parameter dict
    best = dict(study.best_trial.params)
    # Fill defaults and fixed values
    best_params: Dict[str, Any] = {
        'loss_function': 'Logloss',
        'eval_metric': 'AUC',
        'iterations': 4000,
        'od_type': 'Iter',
        'od_wait': 200,
        'task_type': 'CPU',
        'thread_count': -1,
        'bootstrap_type': 'Bayesian',
    }
    best_params.update(best)
    # Recompute auto scale_pos_weight for persistence
    pos = float(y.sum())
    neg = float(len(y) - pos)
    best_params['scale_pos_weight'] = (neg / pos) if pos > 0 else 1.0
    # Ensure integer types for integer params if missing
    if 'depth' in best_params:
        best_params['depth'] = int(best_params['depth'])
    if 'border_count' in best_params:
        best_params['border_count'] = int(best_params['border_count'])
    if 'random_seed' not in best_params:
        best_params['random_seed'] = 42

    print("Best score:", study.best_value)
    print("Best params:", best_params)

    save_best(best_params)

    print('Saved tuned CatBoost params to models/tuned_cat_params.json and models/optimized_params.py (plus root optimized_params.py).')


if __name__ == '__main__':
    main()
